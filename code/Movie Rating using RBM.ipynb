{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1fc937c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### important libraries\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a204ef55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>movie_name</th>\n",
       "      <th>movie_genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children's|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id                          movie_name                   movie_genre\n",
       "0         1                    Toy Story (1995)   Animation|Children's|Comedy\n",
       "1         2                      Jumanji (1995)  Adventure|Children's|Fantasy\n",
       "2         3             Grumpier Old Men (1995)                Comedy|Romance\n",
       "3         4            Waiting to Exhale (1995)                  Comedy|Drama\n",
       "4         5  Father of the Bride Part II (1995)                        Comedy"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### reading movies dataset\n",
    "movies = pd.read_csv('../dataset/Boltzmann_Machines/ml-1m/movies.dat',sep = '::',\n",
    "                    engine = 'python',header = None, encoding = 'latin-1',\n",
    "                     names = ['movie_id','movie_name','movie_genre'])\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b79090e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_gender</th>\n",
       "      <th>user_age</th>\n",
       "      <th>job_id</th>\n",
       "      <th>zip_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>56</td>\n",
       "      <td>16</td>\n",
       "      <td>70072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>55117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>45</td>\n",
       "      <td>7</td>\n",
       "      <td>02460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>55455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id user_gender  user_age  job_id zip_code\n",
       "0        1           F         1      10    48067\n",
       "1        2           M        56      16    70072\n",
       "2        3           M        25      15    55117\n",
       "3        4           M        45       7    02460\n",
       "4        5           M        25      20    55455"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### reading users dataset\n",
    "users = pd.read_csv('../dataset/Boltzmann_Machines/ml-1m/users.dat',sep = '::',\n",
    "                    engine = 'python',header = None, encoding = 'latin-1',\n",
    "                     names = ['user_id','user_gender','user_age','job_id','zip_code'])\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "207c4641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>ratings</th>\n",
       "      <th>timestamps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  ratings  timestamps\n",
       "0        1      1193        5   978300760\n",
       "1        1       661        3   978302109\n",
       "2        1       914        3   978301968\n",
       "3        1      3408        4   978300275\n",
       "4        1      2355        5   978824291"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### reading ratings dataset\n",
    "ratings = pd.read_csv('../dataset/Boltzmann_Machines/ml-1m/ratings.dat',sep = '::',\n",
    "                    engine = 'python',header = None, encoding = 'latin-1',\n",
    "                     names = ['user_id','movie_id','ratings','timestamps'])\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "164ce893",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### prepraring the training and test set\n",
    "\"\"\" Here we will not split the data manually rather use the already splitted (80-20) ratio dataset \n",
    "in our 100k (smaller dataset for education purpose).\"\"\"\n",
    "\n",
    "#### train\n",
    "train1 = pd.read_csv('../dataset/Boltzmann_Machines/ml-100k/u1.base', delimiter = '\\t')\n",
    "train1 = np.array(train1, dtype = 'int64')\n",
    "\n",
    "train2 = pd.read_csv('../dataset/Boltzmann_Machines/ml-100k/u2.base', delimiter = '\\t')\n",
    "train2 = np.array(train2, dtype = 'int64')\n",
    "\n",
    "train3 = pd.read_csv('../dataset/Boltzmann_Machines/ml-100k/u3.base', delimiter = '\\t')\n",
    "train3 = np.array(train3, dtype = 'int64')\n",
    "\n",
    "train4 = pd.read_csv('../dataset/Boltzmann_Machines/ml-100k/u4.base', delimiter = '\\t')\n",
    "train4 = np.array(train4, dtype = 'int64')\n",
    "\n",
    "train5 = pd.read_csv('../dataset/Boltzmann_Machines/ml-100k/u5.base', delimiter = '\\t')\n",
    "train5 = np.array(train5, dtype = 'int64')\n",
    "\n",
    "#### test\n",
    "test1 = pd.read_csv('../dataset/Boltzmann_Machines/ml-100k/u1.test', delimiter = '\\t')\n",
    "test1 = np.array(test1, dtype = 'int64')\n",
    "\n",
    "test2 = pd.read_csv('../dataset/Boltzmann_Machines/ml-100k/u2.test', delimiter = '\\t')\n",
    "test2 = np.array(test2, dtype = 'int64')\n",
    "\n",
    "test3 = pd.read_csv('../dataset/Boltzmann_Machines/ml-100k/u3.test', delimiter = '\\t')\n",
    "test3 = np.array(test3, dtype = 'int64')\n",
    "\n",
    "test4 = pd.read_csv('../dataset/Boltzmann_Machines/ml-100k/u4.test', delimiter = '\\t')\n",
    "test4 = np.array(test4, dtype = 'int64')\n",
    "\n",
    "test5 = pd.read_csv('../dataset/Boltzmann_Machines/ml-100k/u5.test', delimiter = '\\t')\n",
    "test5 = np.array(test5, dtype = 'int64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e820b36e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of users:  943\n",
      "number of movies:  1682\n"
     ]
    }
   ],
   "source": [
    "#### getting the number of users and movies from all split\n",
    "nb_users = int(max(max(train1[:,0]),max(train2[:,0]),max(train3[:,0]),max(train4[:,0]),max(train5[:,0]),\n",
    "                  max(test1[:,0]),max(test2[:,0]),max(test3[:,0]),max(test4[:,0]),max(test5[:,0])))\n",
    "\n",
    "nb_movies = int(max(max(train1[:,1]),max(train2[:,1]),max(train3[:,1]),max(train4[:,1]),max(train5[:,1]),\n",
    "                  max(test1[:,1]),max(test2[:,1]),max(test3[:,1]),max(test4[:,1]),max(test5[:,1])))\n",
    "\n",
    "print('number of users: ',nb_users)\n",
    "print('number of movies: ',nb_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "760478a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### coverting the data into an array with users in lines and movies in columns (required by NN)\n",
    "#### list of list where for each movie list will be a list of all users rating\n",
    "\n",
    "def convert_tolist(data):\n",
    "    new_data = []\n",
    "    for users_id in range(1,nb_users+1):\n",
    "        \"\"\"using nb_user+1 to consider the upper bound of the range\"\"\"\n",
    "        movie_ids = data[:,1][data[:,0] == users_id]\n",
    "        \"\"\"all the movies rated by the users into a list\"\"\"\n",
    "        rating_ids = data[:,2][data[:,0] == users_id]\n",
    "        \"\"\"all the ratings for each movies by the users into a list\"\"\"\n",
    "        ratings_list = np.zeros(nb_movies)\n",
    "        ratings_list[movie_ids-1] = rating_ids\n",
    "        \"\"\"movie_ids -1 because movie_id start at 1 whereas the rating list's index start at 0\"\"\"\n",
    "        new_data.append(list(ratings_list))\n",
    "    return new_data\n",
    "\n",
    "X_train1 = convert_tolist(train1)\n",
    "X_train2 = convert_tolist(train2)\n",
    "X_train3 = convert_tolist(train3)\n",
    "X_train4 = convert_tolist(train4)\n",
    "X_train5 = convert_tolist(train5)\n",
    "\n",
    "X_test1 = convert_tolist(test1)\n",
    "X_test2 = convert_tolist(test2)\n",
    "X_test3 = convert_tolist(test3)\n",
    "X_test4 = convert_tolist(test4)\n",
    "X_test5 = convert_tolist(test5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd58d739",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### coverting the data into Torch tensors\n",
    "X_train1 = torch.FloatTensor(X_train1)\n",
    "X_train2 = torch.FloatTensor(X_train2)\n",
    "X_train3 = torch.FloatTensor(X_train3)\n",
    "X_train4 = torch.FloatTensor(X_train4)\n",
    "X_train5 = torch.FloatTensor(X_train5)\n",
    "\n",
    "X_test1 = torch.FloatTensor(X_test1)\n",
    "X_test2 = torch.FloatTensor(X_test2)\n",
    "X_test3 = torch.FloatTensor(X_test3)\n",
    "X_test4 = torch.FloatTensor(X_test4)\n",
    "X_test5 = torch.FloatTensor(X_test5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d85e45dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### converting the ratings into binary ratings : Liked (1) and Not Liked (0)\n",
    "\n",
    "\"\"\" here we are considering all movies irrespective of whether the movie is rated or watched by the user or not.\n",
    "This refers to BM which try to predict or assign rating to the missing movies \n",
    "(follow conceptual videos for detail) \"\"\"\n",
    "\n",
    "\"\"\" because we are converting the ratings to binary, we will replace 0 with -1 to state missing\n",
    "we will replace 1 abd 2 as not liked and more than 2 as liked\"\"\"\n",
    "\n",
    "X_train1[X_train1 == 0] = -1\n",
    "X_train1[X_train1 == 1] = 0\n",
    "X_train1[X_train1 == 2] = 0\n",
    "X_train1[X_train1 >= 3] = 1\n",
    "\n",
    "X_train2[X_train2 == 0] = -1\n",
    "X_train2[X_train2 == 1] = 0\n",
    "X_train2[X_train2 == 2] = 0\n",
    "X_train2[X_train2 >= 3] = 1\n",
    "\n",
    "X_train3[X_train3 == 0] = -1\n",
    "X_train3[X_train3 == 1] = 0\n",
    "X_train3[X_train3 == 2] = 0\n",
    "X_train3[X_train3 >= 3] = 1\n",
    "\n",
    "X_train4[X_train4 == 0] = -1\n",
    "X_train4[X_train4 == 1] = 0\n",
    "X_train4[X_train4 == 2] = 0\n",
    "X_train4[X_train4 >= 3] = 1\n",
    "\n",
    "X_train5[X_train5 == 0] = -1\n",
    "X_train5[X_train5 == 1] = 0\n",
    "X_train5[X_train5 == 2] = 0\n",
    "X_train5[X_train5 >= 3] = 1\n",
    "\n",
    "X_test1[X_test1 == 0] = -1\n",
    "X_test1[X_test1 == 1] = 0\n",
    "X_test1[X_test1 == 2] = 0\n",
    "X_test1[X_test1 >= 3] = 1\n",
    "\n",
    "X_test2[X_test2 == 0] = -1\n",
    "X_test2[X_test2 == 1] = 0\n",
    "X_test2[X_test2 == 2] = 0\n",
    "X_test2[X_test1 >= 3] = 1\n",
    "\n",
    "X_test3[X_test3 == 0] = -1\n",
    "X_test3[X_test3 == 1] = 0\n",
    "X_test3[X_test3 == 2] = 0\n",
    "X_test3[X_test3 >= 3] = 1\n",
    "\n",
    "X_test4[X_test4 == 0] = -1\n",
    "X_test4[X_test4 == 1] = 0\n",
    "X_test4[X_test4 == 2] = 0\n",
    "X_test4[X_test4 >= 3] = 1\n",
    "\n",
    "X_test5[X_test5 == 0] = -1\n",
    "X_test5[X_test5 == 1] = 0\n",
    "X_test5[X_test5 == 2] = 0\n",
    "X_test5[X_test5 >= 3] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94fad905",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Creating the architecture of the Neural Network\n",
    "class RBM():\n",
    "    \n",
    "    def __init__(self, num_visible_nodes, num_hidden_nodes):\n",
    "        \n",
    "        \"\"\" assignment weights (normally distributed) based on number of visible and hidden nodes\"\"\"\n",
    "        self.Weight = torch.randn(num_hidden_nodes,num_visible_nodes) #100*1682 \n",
    "        \n",
    "        \"\"\" bias based on probability of hidden nodes given the visible node and vise versa - \n",
    "        the arguements are batch size (1) and the corresponding number\"\"\"\n",
    "        self.bias_visible_node = torch.randn(1,num_visible_nodes) #1*100 \n",
    "        self.bias_hidden_node = torch.randn(1,num_hidden_nodes) #1*1682\n",
    "        \n",
    "    \"\"\"sigmoid activation function - gibb sampling for loglikelihood gradient - to estimate the probability\n",
    "    of hidden nodes given the visible nodes - sample the activations of the hidden nodes - \n",
    "    This function will sample the activations of each of the hidden nodes according to the probability of \n",
    "    hidden nodes given Visible nodes and vice versa\"\"\"\n",
    "    \n",
    "    def sample_hidden(self, x):\n",
    "        \n",
    "        \"\"\"X corresponds to the visible neurons (V) in the probabilities , p(h) given V\"\"\"\n",
    "        \"\"\"product of Weight and probability - here weight's transpose is consider for correct calculations\"\"\"\n",
    "        wx = torch.mm(x, self.Weight.t()) #100*1682 * 1682*100 = 100*100\n",
    "        \n",
    "        \"\"\"activation function = linear function+bias - here expand fn is used for each weights + bias,\n",
    "        this activation function gives the probabilty  that the hidden node will be activated \n",
    "        according to the value of visible node\"\"\"\n",
    "        activation = wx + self.bias_hidden_node.expand_as(wx) \n",
    "        \n",
    "        \"\"\"calculate probabilty of hidden given visible (suppose user like drama movies ,\n",
    "        hidden nodes having drama will have higher probability) - use sigmoid function\"\"\"\n",
    "        p_h_given_v = torch.sigmoid(activation) #100*100\n",
    "        \n",
    "        \"\"\" we are using Bernoulli RBM, because our ratings are binary. We need Bernoulli samples - \n",
    "        if p_h_given_v  >= 0.7 (70%), we will activate the neuron else not \"\"\"\n",
    "        return p_h_given_v, torch.bernoulli(p_h_given_v)\n",
    "    \n",
    "    def sample_visible(self, y):\n",
    "        \n",
    "        \"\"\"y corresponds to the hidden neurons (h) in the probabilities , p(v) given h - no transpose\"\"\"\n",
    "        wy = torch.mm(y, self.Weight) #100*100 * 100*1682 = 100*1682\n",
    "        \n",
    "        \"\"\"activation function = linear function+bias - here expand fn is used for each weights + bias,\n",
    "        this activation function gives the probabilty  that the visible node will be activated \n",
    "        according to the value of hidden node\"\"\"\n",
    "        activation = wy + self.bias_visible_node.expand_as(wy)\n",
    "        \n",
    "        \"\"\"calculate probabilty of visible given hidden - use sigmoid function\"\"\"\n",
    "        p_v_given_h = torch.sigmoid(activation) #100*1682\n",
    "        \n",
    "        \"\"\" we are using Bernoulli RBM, because our ratings are binary. We need Bernoulli samples\"\"\"\n",
    "        return p_v_given_h, torch.bernoulli(p_v_given_h)\n",
    "    \n",
    "    \"\"\"contrastive divergence - input V0 - all ratings of one user(it will iterate for all users) \n",
    "    input vk - visible nodes obtained after k samplings  \n",
    "    (k trips(k iterations and k contrastive divergence) from visible to hidden to visible) - \n",
    "    input ph0 - probability of first hidden node given visible node. - input phk - \n",
    "    probabilities of the hidden nodes after k sampling given the values of visible nodes VK\"\"\"\n",
    "    \n",
    "    def train(self, v0, vk, ph0, phk):\n",
    "        self.Weight += (torch.mm(v0.t(), ph0)  - torch.mm(vk.t(), phk)).t() #100*1682\n",
    "        #!= 1682*100 * 100*100 - 1682*100 * 100*100 = 1682*100\n",
    "        \n",
    "        \"\"\"zero to keep the dimension of tensor 2D\"\"\"\n",
    "        self.bias_visible_node += torch.sum((v0 - vk), 0) \n",
    "        self.bias_hidden_node += torch.sum((ph0 - phk), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b616365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 loss: tensor(0.3231)\n",
      "epoch: 2 loss: tensor(0.2338)\n",
      "epoch: 3 loss: tensor(0.2461)\n",
      "epoch: 4 loss: tensor(0.2492)\n",
      "epoch: 5 loss: tensor(0.2486)\n",
      "epoch: 6 loss: tensor(0.2476)\n",
      "epoch: 7 loss: tensor(0.2447)\n",
      "epoch: 8 loss: tensor(0.2502)\n",
      "epoch: 9 loss: tensor(0.2455)\n",
      "epoch: 10 loss: tensor(0.2492)\n",
      "epoch: 11 loss: tensor(0.2452)\n",
      "epoch: 12 loss: tensor(0.2476)\n",
      "epoch: 13 loss: tensor(0.2471)\n",
      "epoch: 14 loss: tensor(0.2493)\n",
      "epoch: 15 loss: tensor(0.2475)\n",
      "epoch: 16 loss: tensor(0.2494)\n",
      "epoch: 17 loss: tensor(0.2451)\n",
      "epoch: 18 loss: tensor(0.2467)\n",
      "epoch: 19 loss: tensor(0.2470)\n",
      "epoch: 20 loss: tensor(0.2479)\n"
     ]
    }
   ],
   "source": [
    "#### variable assignment\n",
    "\n",
    "\"\"\" here the number of visible node = number of movies\"\"\"\n",
    "nv = len(X_train1[0])\n",
    "\n",
    "\"\"\" here number of hidden nodes are arbitary (how many hidden features to calculate) - can be tuned further\"\"\"\n",
    "nh = 100\n",
    "\n",
    "\"\"\"additional batchsize for overal batch train \"\"\"\n",
    "batch_size = 100\n",
    "\n",
    "\"\"\"RBM object\"\"\"\n",
    "rbm = RBM(nv,nh)\n",
    "\n",
    "#### training the RBM \n",
    "\n",
    "\"\"\"number of epochs\"\"\"\n",
    "nb_epoch = 20\n",
    "\n",
    "\"\"\"training loop\"\"\"\n",
    "for epoch in range(1,nb_epoch+1):\n",
    "    \"\"\"declaring training_loss and counter\"\"\"\n",
    "    training_loss = 0\n",
    "    count = 0.0\n",
    "    \"\"\" we have to pass batch of users (not single user) for training\"\"\"\n",
    "    for users_id in range(0,nb_users - batch_size,batch_size):\n",
    "        \"\"\"initialize nput V0 - all ratings of batch of user(it will iterate for all users) \n",
    "        input vk - visible nodes obtained after k samplings (initially vk = v0 , will be updated with epochs) \n",
    "        (k trips(k iterations and k contrastive divergence) from visible to hidden to visible) - \n",
    "        input ph0 - probability of first hidden node given visible node. - input phk - \n",
    "        probabilities of the hidden nodes after k sampling given the values of visible nodes VK\"\"\"\n",
    "        vk = X_train1[users_id:users_id+batch_size]\n",
    "        v0 = X_train1[users_id:users_id+batch_size]\n",
    "        ph0,_ = rbm.sample_hidden(v0)\n",
    "        \n",
    "        \"\"\"k = 10 steps for constrastive divergence\"\"\"\n",
    "        for k in range(10):\n",
    "            \n",
    "            \"\"\"updating hidden nodes and visible nodes (constrastive divergence) for each iteration for each batch\"\"\"\n",
    "            \"\"\"first input to create hidden - hidden to output visible and so on\"\"\"\n",
    "            _,hk = rbm.sample_hidden(vk)\n",
    "            _,vk = rbm.sample_visible(hk)\n",
    "            \n",
    "            \"\"\"fixing (we are not updating the -1 ratings(missing)) the negative rating weights\"\"\"\n",
    "            vk[v0<0] = v0[v0<0]\n",
    "        \"\"\"phk for updated vk\"\"\"\n",
    "        phk,_ = rbm.sample_hidden(vk)\n",
    "        \n",
    "        \"\"\"training with updated values\"\"\"\n",
    "        rbm.train(v0, vk, ph0, phk )\n",
    "        \n",
    "        \"\"\"updating training loss and counter - for all non negative values\"\"\"\n",
    "        training_loss += torch.mean(torch.abs(v0[v0>=0] - vk[v0>=0]))\n",
    "        count += 1\n",
    "    \n",
    "    \"\"\"Average Distance training loss\"\"\"\n",
    "    print('epoch: '+str(epoch)+ ' loss: '+str(training_loss/count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "27a00d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: tensor(0.2460)\n"
     ]
    }
   ],
   "source": [
    "#### testing \n",
    "\n",
    "\"\"\"declaring test_loss and counter\"\"\"\n",
    "test_loss = 0\n",
    "count = 0.0\n",
    "\"\"\" we don't need batch of users (we need all single users) for testing - batch_size = 1\"\"\"\n",
    "for users_id in range(0,nb_users):\n",
    "\n",
    "    \"\"\"we have two inputs v = ratings of training set which is needed to activate hidden neurons \n",
    "    so it can predict the output vt = input of test set\"\"\"\n",
    "    v = X_train1[users_id:users_id+1]\n",
    "    vt = X_test1[users_id:users_id+1]\n",
    "\n",
    "    \"\"\"we have already trained our model to perform the best using constrastive divergence of 10 steps,\n",
    "    we don't need 10 steps for prediction, but only 1. Also we need to predict for values of non negative\"\"\"\n",
    "    if len(vt[vt>=0])>0:\n",
    "\n",
    "        \"\"\"updating hidden nodes and visible nodes\"\"\"\n",
    "        \"\"\"first input to create hidden - hidden to output visible \"\"\"\n",
    "        _,h = rbm.sample_hidden(v)\n",
    "        _,v = rbm.sample_visible(h)\n",
    "\n",
    "        \"\"\"updating testing loss and counter - for all non negative values\"\"\"\n",
    "        test_loss += torch.mean(torch.abs(vt[vt>=0] - v[vt>=0]))\n",
    "        count += 1\n",
    "\n",
    "\"\"\"Average Distance testing loss\"\"\"\n",
    "print('test_loss: '+str(test_loss/count))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
